# lstm-memory-cell1024 train config


# 3. LSTM model (Section 2).
# cell of LSTM is 1024.
# layer of LSTM is 2.
# mixture of MoE is 8.

# use l2-norm and tf's cross loss function

# model setting
name: lstm-memory-cell1024
EX_ID: EX12
batchsize: 32
moe_num_mixtures: 8
frame_level_model: lstm_memory_model
video_level_model: LogisticModel
lstm_cells: 1024
lstm_layers: 2
rnn_swap_memory: true
model_checkpoint_path: null
scale: 32
fix_length: 12

# train setting
one_hot: false
base_learning_rate: 0.0001
learning_rate_decay: 0.7
decay_at_epoch: 5
num_epochs: 81
max_step: null
optimize: AdamOptimizer
noise_level: null
dropout: true
keep_prob: 0.7
keep_checkpoint_every_n_hour: 2
max_to_keep: 10
regularization_penalty: 0.0001
device_id:
- 2
- 3

# dataset seting
vocab_size: 500

# train path
train_dir: /mnt/md0/LSVC/ExWorkSpace/lstm_memory_cell_1024_ex12/

