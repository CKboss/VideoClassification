# lstm-memory-cell1024 train config


# 3. LSTM model (Section 2).
# cell of LSTM is 1024.
# layer of LSTM is 2.
# mixture of MoE is 8.

# model setting
name: lstm-memory-cell1024
EX_ID: EX1
batchsize: 64
moe_num_mixtures: 8
frame_level_model: lstm_memory_model
video_level_model: moe_model
lstm_cells: 1024
lstm_layers: 2
rnn_swap_memory: true
#model_checkpoint_path: null
model_checkpoint_path: /mnt/md0/LSVC/ExWorkSpace/lstm_memory_cell_1024_ex1/lstm-memory-cell1024_EX1_save000.ckpt-0

# train setting
base_learning_rate: 0.001
learning_rate_decay: 0.1
decay_at_epoch: 10
num_epochs: 5
max_step: null
optimize: AdamOptimizer
dropout: null
noise_level: 0
keep_prob: 1.0
keep_checkpoint_every_n_hour: 2
max_to_keep: 10
regularization_penalty: 0.0001
device_id: '/gpu:1'

# dataset seting
vocab_size: 500

# train path
train_dir: '/mnt/md0/LSVC/ExWorkSpace/lstm_memory_cell_1024_ex1/'
