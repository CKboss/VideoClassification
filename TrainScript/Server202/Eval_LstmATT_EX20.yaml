# 2017-09-06 15:32:50,483-LstmAttentionLstmModel_EX_20-INFO: train_config:  # Attion lstm
# description of the train config
# model setting

name: Eval_LstmAttentionLstmModel

EX_ID: EX_20

batchsize: 32

moe_num_mixtures: 4

frame_level_model: LstmAttentionLstmModel

video_level_model: moe_model

lstm_cells: 1024

lstm_layers: 2

rnn_swap_memory: true

model_checkpoint_path: /datacenter/1/LSVC/downloads/LstmAttention_EX20/LstmAttentionLstmModel_EX_20_save12000.ckpt-12000
scale: 3

fix_length: 64

# train setting

one_hot: true

base_learning_rate: 0.00001

learning_rate_decay: 0.8

decay_at_step: 25000

num_epochs: 91

max_step: null

max_step: null

optimize: AdamOptimizer

keep_checkpoint_every_n_hour: 2

max_to_keep: 10

regularization_penalty: 0.00001

device_id:

- 5

# dataset seting

vocab_size: 500

# train path

train_dir: /datacenter/1/LSVC/ExWorkSpace/Eval_LstmAttentionModel_EX20/